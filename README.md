# TextShield

TextShield is an AI-powered content moderation assistant. It detects and filters hate speech, bullying, and toxic language in real-time using NLP models. Designed for integration with chat platforms, forums, and apps that care about safe communication.

## Features

- Hate speech detection
- Toxic comment filtering
- Real-time analysis
- Admin feedback dashboard (planned)
